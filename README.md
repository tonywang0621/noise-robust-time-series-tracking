# Week 1 – Data Generation and Visualization

## Motivation
In many real-world time-series problems, the true system state evolves over time but cannot be directly observed due to noise. 
Instead, we only have access to noisy measurements that partially reflect the underlying state.

Before applying any estimation or machine learning method, it is crucial to understand how such data is generated and how noise affects observations.

This week focuses on building a simple noisy dynamic system and visualizing the relationship between the hidden state and noisy observations.

---

## System Description
We consider a one-dimensional discrete-time dynamic system with the following assumptions:

### Hidden State (Process Model)
The true system state evolves as a random walk:

$x_{t+1} = x_t + w_t,\quad w_t \sim \mathcal{N}(0, Q)$


where:
- $x_t\$ is the hidden (unobserved) true state,
- $w_t\$ is the process noise,
- $Q\$ controls how much the true state fluctuates over time.

### Observation Model
The observed measurement is a noisy version of the true state:

$y_t = x_t + v_t, \quad v_t \sim \mathcal{N}(0, R)$




where:
- $y_t\$ is the observed value,
- $v_t\$ is the measurement noise,
- $R\$ controls the noise level of the observation.

---

## Data Generation
Synthetic time-series data is generated by:
1. Simulating the hidden state sequence using the random walk model.
2. Adding Gaussian measurement noise to produce noisy observations.

Both process noise variance $Q\$ and measurement noise variance $R\$ are adjustable to study their effects.

---

## Visualization
We visualize:
- The hidden true state as a continuous line.
- The noisy observations as scattered points.

This comparison highlights the key challenge of time-series tracking:
> Noisy observations do not directly reveal the true system state.

---

## Key Observations
From the visualization:
- Larger $Q\$ leads to a more volatile true state.
- Larger $R\$ results in noisier observations.
- Noisy measurements alone can be misleading without considering the underlying dynamics.

---

## Next Step
In Week 2, we will apply simple baseline methods (naive estimation, moving average, and regression-based approaches) to estimate the hidden state and evaluate their performance.

# Week 2 – Baseline Methods under Noisy Observations

## Purpose of Baselines
Before applying any advanced filtering or model-based estimation method, it is important to understand how simple and intuitive approaches behave under noisy conditions.

In this week, several baseline methods are introduced to establish reference points for comparison. These baselines help clarify the limitations of observation-only and data-driven approaches, and motivate the need for a more principled state estimation framework.

---

## Baseline Methods

### Naive Baseline
The naive baseline directly uses the noisy observation as the estimate of the system state:
- No noise handling
- No temporal modeling

This baseline represents the lower bound of performance and serves as a reference for the worst-case scenario.

---

### Moving Average Baseline
The moving average baseline smooths the noisy observations by averaging the most recent measurements within a fixed window.

- Effectively reduces measurement noise
- Introduces temporal lag when the true state changes
- Does not distinguish between noise and genuine state transitions

This method highlights the trade-off between noise reduction and responsiveness.

---

### Linear Regression Baseline
The regression-based baseline predicts the current state using a linear combination of past observations.

- Purely data-driven
- Does not assume any system dynamics
- Sensitive to measurement noise
- May overfit noisy observations

This baseline represents the simplest form of machine learning without explicit modeling of the underlying process.

---

## Key Observations
From the experimental results and visual comparisons:

- The naive baseline closely follows noisy observations and is highly sensitive to measurement noise.
- Moving average smoothing reduces noise but consistently lags behind the true state, especially when the state changes rapidly.
- Linear regression captures short-term trends but can become unstable under high noise levels and tends to track noise rather than the underlying state.

These results demonstrate that observation-based and data-driven methods alone are insufficient for reliable state estimation in noisy dynamic systems.

---

## Motivation for Next Step
The limitations observed in the baseline methods motivate the use of model-based filtering approaches.

An effective estimator should:
- Reduce measurement noise without introducing excessive lag
- Incorporate knowledge of system dynamics
- Balance trust between observations and model predictions

In Week 3, a Kalman filter will be introduced to address these challenges by explicitly modeling state evolution and uncertainty.
